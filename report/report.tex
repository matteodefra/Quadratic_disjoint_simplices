\documentclass[notitlepage]{article}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{algorithm}% http://ctan.org/pkg/algorithm
% \usepackage{algorithmic}
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage[utf8]{inputenc}
\usepackage[top=0.5cm, left=0.5cm, right=0.5cm, bottom=1.5cm]{geometry}
\usepackage{accents}
\usepackage{float}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{pdfpages}
\usepackage{sectsty}
\usepackage{ragged2e}
\usepackage{titlesec}
\usepackage{listings}
\usepackage{etoolbox}
\usepackage[outline]{contour}
\usepackage[font=small,skip=1pt]{caption}
\usepackage{enumitem}
\usepackage{tikz}
\usetikzlibrary{arrows}
%Includes "References" in the table of contents
\usepackage[nottoc]{tocbibind}
\usepackage{appendix}

\setlength\parindent{0pt}

\newcommand{\myrule} [3] []{
    \begin{center}
        \begin{tikzpicture}
            \draw[#2-#3, ultra thick, #1] (0,0) to (0.2\linewidth,0);
        \end{tikzpicture}
    \end{center}
}

\titleformat{\chapter}[block]
  {\normalfont\huge\bfseries}{\thechapter.}{10pt}{\huge}
\titlespacing*{\chapter}{0pt}{0pt}{10pt}

\makeatletter
\patchcmd{\chapter}{\if@openright\cleardoublepage\else\clearpage\fi}{}{}{}
\makeatother

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\newcommand{\ubar}[1]{\underaccent{\bar}{#1}}
\newcommand{\e}[1]{\cdot10^{#1}}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}


\title{Project Non-ML 5}
\author{Matteo De Francesco}
\date{}
\begin{document}

\maketitle

\thispagestyle{empty}

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}
In this report we will analize the convex quadratic problem
\begin{equation}
    \min \left\lbrace x^T Q x + q x : \sum_{i \in I^k} x_i = 1, k\in K, x \ge 0 \right\rbrace
    \label{eqn:problem} \tag{$P$}
\end{equation}
with the following constraints: $x \in \mathbb{R}^n$, the index sets $I^k$ form a partition of the set $\{1,\ldots,n\}$ (i.e.$ \cup_{k\in K} I^k = \{ 1,\ldots,n \}$, and $I^h \cap I^k = \emptyset $ for all
$h$ and $k$), and $Q$ is positive semidefinite.\\
% This is a quadratic problem with a simplicial complex constraint, so the objective, in terms of the primal problem, is finding the x (the simplicial complex) which lies in the minimum of our quadratic function.\\
The aim of this project is to exploit the Lagrangian dual problem and solve it via one of the \textit{deflected subgradient} methods.\\
We can identify the inequality and equality constraints and rewrite them in the typical form
\begin{gather*}
  G(x) \rightarrow g_i(x) \le 0 \implies -x_i \le 0 \ \forall i \in \{1,\ldots,n\} \\
  H(x) \rightarrow h_j(x) = 0 \implies \sum_{i \in I^k} x_i - 1 = 0 \ \forall k \in K
\end{gather*}    
Hence we can rewrite the problem in the following form:
\begin{align*}
  \begin{cases}
    \min\  x^T Q x + q x \\
    -x_i \le 0 \ \forall\, i \in \{1,\ldots,n\} \\
    \sum_{i \in I^k} x_i - 1 = 0 \ \forall\, k \in K
  \end{cases}    
\end{align*}
In order to have less dual variables, we can rewrite the above problem as a lagrangian function of only the inequality constraints:
\begin{align*}
  \mathcal{L}(x;\lambda) = x^T Q x + q x - \left\langle \lambda,x \right\rangle 
\end{align*}
% {\large Make the dual function depending only on $\lambda$ and "ignore" the equality constraints $\mu$. In this way the relaxed problem is much more easier since we have only to optimize dual variables $\mu$}.\\
% and then applying the Lagrangian duality we can write the function
% \begin{equation}
%   L(x;\lambda,\mu) = x^T Q x + q x - \sum_{j=1}^n \lambda_j x_j + \sum_{k=1}^{|K|} \left( \mu_k \sum_{i \in I^k} x_i - 1 \right) = x^T Q x + q x - \left\langle \lambda,x \right\rangle + \left\langle \mu,\sum_{i \in I^k} x_i - 1 \right\rangle
% \end{equation}
% where the vector $\lambda \in \mathbb{R}_+^n$ and $\mu \in \mathbb{R}^{|K|}$.\\
Now, we can easily construct the lagrangian dual function considering the equality constraints
\[
  \psi(\lambda) = \min_{x \in \mathcal{Y}} \left\lbrace \mathcal{L}(x;\lambda) ,\ \lambda \ge 0 \right\rbrace
\]
where $\mathcal{Y} = \{\sum_{i \in I^k} x_i = 1 \ \forall\, k \in K\}$. Hence the following optimization problem
\begin{equation}
  \begin{cases}
    \max_{\lambda}\  \psi(\lambda)  \\
    \text{subject to } \lambda \ge 0 
  \end{cases}
  \label{eqn:dual_problem}  
  \tag{$D$}
\end{equation}
We are assuming that optimizing over the set $\mathcal{Y}$ can be done very easily.\\ 
In the next section, we will briefly recall the properties of the \texttt{ADAGRAD} family of algorithms\cite{JMLR:v12:duchi11a}.% and analyze it in our problem setting.

% Now, our problem reduced to solving the Lagrangian dual function relaxation 
% \[
%   \psi(\lambda,\mu) = \min_x \{ L(x;\lambda,\mu) : x \in \mathbb{R}^n \}
% \]
% which we know being surely concave. Hence the following optimization problem
% \begin{equation}
%   \begin{cases}
%     \max_{\lambda,\mu}\  \psi(\lambda,\mu)  \\
%     \text{subject to } \lambda \ge 0 
%   \end{cases}
%   \label{eqn:dual_problem}  
% \end{equation}
% In the next section, we will briefly recall the properties of the \texttt{ADAGRAD} family of algorithms\cite{JMLR:v12:duchi11a} and analyze it in our problem setting.

\section{Deflected subgradient Analysis}
% Deflected subgradient are a general method aimed to modify the direction of the update through a convex combination $\alpha \in \left[0,1\right]$ in order to have a $\left\langle d_k,d_{k+1} \right\rangle \ge 0$. In this way, we dampen the zig-zag behavior 
% of the standard gradient descent and we exploit non differentiable settings. As summed up in \cite{Frangioni2017}, different variations of the subgradient method can be derived, based on the different choice of directions $d_k$, subgradient $g_k$ and their 
% relative projections.\\
% Also subgradient methods divide in two different categories: stepsize restricted rules, and deflection restricted rules.\\
% One of the most popular subgradient methods is the \texttt{PRIMAL-DUAL} approach, where both stepsize and deflection are computed simultaneously through the Sample Average (SA) or the Weighted Average (WA). Both \cite{Frangioni2017} and \cite{JMLR:v12:duchi11a}
% explore this method, originally mentioned in \cite{Nesterov2009}. In the first case, it is mentioned in the appendix A and we have a proof of convergence. In the second case, it is used directly to update the current value.\\
% The PDSM (primal-dual subgradient method) is based on the assumption of having a proximal function inside the general update. This is reported in \cite{Frangioni2017} in Appendix A and also in \cite{JMLR:v12:duchi11a}, where the proximal function is directly 
% used inside the update with a precise value.\\
% The use of proximal functions is derived particurarly in \cite{JMLR:v12:duchi11a} in section 2, where boundaries for the proximal functions are obtained.

% ADAGRAD ANALYSIS
\subsection{\texttt{ADAGRAD} introduction}
The projection rule of a point $y$ onto the constraint set $\mathcal{X}$ according to a positive semidefinite matrix $A$ amounts to:
\[ \prod_\mathbb{X}^A (y) = \argmin_{\lambda \in X} \| \lambda-y \|_A = \argmin_{\lambda \in X} \left\langle \lambda-y,A(\lambda-y) \right\rangle \]
and it's aimed to minimize the Mahalanobis norm.\\
\texttt{ADAGRAD} applies the following projection rule:
\begin{equation}
  \lambda_{t+1} = \prod_\mathcal{X}^{diag(G_t)^{1/2}} (\lambda_t - \eta \, diag(G_t)^{-1/2} g_t) 
  \label{eqn:projection}
\end{equation}
where the matrix $A$ coincides with the diagonal square root of the full outer product of the subgradients $G_t = \sum_{\tau=1}^t g_\tau g_\tau^T$.
% The constraint set $\mathcal{X}$ coincide with the constraints of disjoint simplices, thus resulting 
% in a constraint set coincident with a simplicial complex. So we have to project points of our original quadratic problem onto a simplicial complex .\\
As we stated in the introduction, we should exploit \texttt{ADAGRAD} on the dual problem, whose constraint set consists in the simple inequality constraint $\lambda \ge 0$, which is addressable by \texttt{ADAGRAD},
given the fact that the algorithm can be applied to any convex set $\mathcal{X} \subseteq \mathbb{R}^n$, respected by our problem (we are in $\mathbb{R}_+^n$).\\
In addition, as the general projection rule tell us, the new update $\lambda_{t+1}$ is projected over the constraint set $\mathcal{X}$ according to the matrix of the gradients.\\
% Not only, since we are using the PDSM (primal-dual subgradient methods) update rule inside the \texttt{ADAGRAD} framework, \texttt{LEMMA} 2 of \cite{Frangioni2017} in Appendix A give us a proof of the convergence of the method over the space $\mathbb{R}_+^n$, 
% which coincide exactly with our setting.\\
We will recall in the next section some algorithmic properties of the algorithm convergence for diagonal matrices, and we will derive the update rule followed by the projection over the constraint set $\mathcal{X} = \{\lambda \ge 0\}$.

\subsection{Algorithm characteristics}
First of all, we reiterate that \texttt{ADAGRAD} is suitable for the dual problem, given its application in a convex setting. The goal is to attain a small regret bound:
\begin{equation}
  R_\phi (T) \triangleq \sum_{t=1}^T \psi(\lambda_t) - \psi(\lambda^*)
\end{equation}
between the actual value of the dual function $\psi$ with the corresponding iterate $\lambda$ at step $t$ and the value of $\psi$ with the optimal solution $\lambda^*$.\\
The point of \texttt{ADAGRAD} is that not all features are equal, hence they must be treated differently. That's the purpose of using an adaption to the geometry of space, so do not use anymore a standard gradient descent but conditioning 
the different values based on a positive semidefinite matrix $A$ (the $G_t$ in this case).\\
Two algorithm versions are analyzed in \cite{JMLR:v12:duchi11a}, where we omitted the regularization term due to our problem setting. The first update, referred to as \textit{primal-dual subgradient method}, is 
\begin{equation}
  \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle \overline{g}_t,\lambda \right\rangle + \frac{1}{t} \Psi_t(\lambda) \}
  \label{eqn:primal-dual-update}
\end{equation}
coming from \cite{NIPS2009_7cce53cf}, where $\overline{g}_t = \frac{1}{t} \sum_{\tau=1}^t g_\tau$ is the average gradient, $\eta$ is a fixed stepsize and $\Psi_t$ is the \textit{proximal term}.\\
The second update instead
\begin{equation}
  \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle g_t,\lambda \right\rangle + B_{\Psi_t} (\lambda,\lambda_t) \}
  \label{eqn:composite-mirror-update}
\end{equation}
where $B$ refers to the Bregman divergence. This second update comes from \cite{inproceedings}.\\
Finally, also the previous mentioned projection rule can be used as an update:
\begin{equation}
  \lambda_{t+1} = P_{\mathcal{X}} \{ \lambda_t - \eta\, diag(G_t)^{-1/2} g_t \}
  \label{eqn:standard-rule}
\end{equation}
where $P$ denotes the projection operation. The proximal term $\Psi_t$ is the key point of the algorithm. Instead of using a fixed proximal functions, both the updates use squared Mahalanobis norms as their proximal functions, setting then $\Psi_t(\lambda) = \left\langle \lambda,H_t \lambda \right\rangle$ 
for a symmetric matrix $H_t \succeq 0$. In particular, the diagonal case which we will recall here make use of:
\[ H_t = \delta I + diag(G_t)^{1/2} \]
for some smalled fixed $\delta \ge 0$.\\
The usage of a strongly convex proximal function is also remarked in \cite{Frangioni2017} in appendix A.

\subsection{Proximal term discussion}
In order to attain a lower regret bound and to adapt to the geometry of the space, the objective of the authors is to not use anymore a standard proximal functions but a modified version of it.\\
The proximal function act as a regularization term, typically the Euclidian projection over a convex set. Given the indicator function of a convex set $C$:
\begin{align*}
  I_C(\lambda) = \begin{cases}
    0 \quad \lambda \in C \\
    +\infty \quad \text{otherwise}
  \end{cases}
\end{align*}
the standard proximal mapping of $I_C$ is the Euclidean projection on $C$:
\begin{align*}
  prox_{I_C}(\lambda) = \argmin_{u \in C} \| u - \lambda \|_2^2 = P_C(\lambda)
\end{align*}
Instead in this case the authors noticed that some local region of the function to be optimized need more "attention than others". What they come up with then is the modification (also remarked in the \texttt{ADAGRAD} introduction) using a different proximal function where  
\begin{align*}
  prox_{I_C}(\lambda) = \argmin_{u \in C} \| u - \lambda \|_A^2 = P_C(\lambda)
\end{align*}
the Euclidean projection is not computed anymore according to a 2-norm, but according to a matrix $A$ which in the case of \texttt{ADAGRAD} coincide with the matrix of the subgradients. A summary of the properties and aspects of some proximal functions 
can be found in \cite{OPT-003}. Below is reported the analysis of the proximal function regarding \cite{JMLR:v12:duchi11a}.\\
Examining the regret bounds for the updates in \cite{Nesterov2009} and \cite{NIPS2009_7cce53cf}, it is quite obvious that they depends on dual norms of the derivative of the function to be optimized, and in turn this last depend on the choice of $\Psi$. The objective of \cite{JMLR:v12:duchi11a} 
is to properly modify the value of $\Psi$ during the run of the algorithm in order to lower the contribution of the norms, and so lower the regret bound. This is achieved by keeping second order information about the sequence of iterates $\lambda_t$ and allow $\Psi$ 
to vary on each round of the algorithm. To achieve this, we must assume that $\Psi_t$ is monotically non-decreasing, 1-strongly convex with respect to a time-dependent semi-norm $\|\cdot\|_{\Psi_t}$. Formally, given two generic points $x$ and $y$, $\Psi$ is 1-strongly convex with respect 
to $\|\cdot\|_\Psi$ if
\[ \Psi(y) \ge \Psi(x) + \left\langle \nabla \Psi(x),y-x \right\rangle + \frac{1}{2} \|x-y\|_\Psi^2 \]
As a consequence, strong convexity is guaranteed if and only of $B_{\Psi_t}(x,y) \ge \frac{1}{2} \|x-y\|_{\Psi_t}^2$. The following bound holds then on proximal term, respectively for \eqref{eqn:primal-dual-update} and \eqref{eqn:composite-mirror-update}. 
Proofs can be found in Appendix F of \cite{JMLR:v12:duchi11a}.
% \begin{proposition}
%   Let the sequence $\{x_t\}$ be defined by the update \eqref{eqn:primal-dual-update}. For any $x^* \in \mathcal{X}$
%   \begin{equation}
%     \sum_{t=1}^T f_t(x_t) + \varphi(x_t) - f_t(x^*) - \varphi(x^*) \le \frac{1}{\eta} \Psi_T(x^*) + \frac{\eta}{2} \sum_{t=1}^T \| f_t'(x_t) \|_{\Psi_{t-1}^*}^2
%   \end{equation}
% \end{proposition}
% \begin{proposition}
%   Let the sequence $\{x_t\}$ be defined by the update \eqref{eqn:composite-mirror-update}. Assume w.l.o.g. that $\varphi(x_1)=0$. For any $x^* \in \mathcal{X}$
%   \begin{equation}
%     \sum_{t=1}^T f_t(x_t) + \varphi(x_t) - f_t(x^*) - \varphi(x^*) \le \frac{1}{\eta} B_{\Psi_1} (x^*,x_1) + \frac{1}{\eta} \sum_{t=1}^{T-1} \left[ B_{\Psi_{t+1}}(x^*,x_{t+1}) - B_{\Psi_t}(x^*,x_{t+1}) \right] + \frac{\eta}{2} \sum_{t=1}^T \|f_t'(x_t) \|_{\Psi_t^*}^2
%   \end{equation}
% \end{proposition}
\begin{proposition}
  Let the sequence $\{\lambda_t\}$ be defined by the update \eqref{eqn:primal-dual-update}. For any $\lambda^* \in \mathcal{X}$
  \begin{equation}
    \sum_{t=1}^T \psi(\lambda_t) - \psi(\lambda^*) \le \frac{1}{\eta} \Psi_T(\lambda^*) + \frac{\eta}{2} \sum_{t=1}^T \| \psi'(\lambda_t) \|_{\Psi_{t-1}^*}^2
  \end{equation}
\end{proposition}
\begin{proposition}
  Let the sequence $\{\lambda_t\}$ be defined by the update \eqref{eqn:composite-mirror-update}. For any $\lambda^* \in \mathcal{X}$
  \begin{equation}
    \sum_{t=1}^T \psi(\lambda_t) - \psi(\lambda^*) \le \frac{1}{\eta} B_{\Psi_1} (\lambda^*,\lambda_1) + \frac{1}{\eta} \sum_{t=1}^{T-1} \left[ B_{\Psi_{t+1}}(\lambda^*,\lambda_{t+1}) - B_{\Psi_t}(\lambda^*,\lambda_{t+1}) \right] + \frac{\eta}{2} \sum_{t=1}^T \| \psi'(\lambda_t) \|_{\Psi_t^*}^2
  \end{equation}
\end{proposition}
The proximal term and the bregman divergence present in \eqref{eqn:primal-dual-update} and \eqref{eqn:composite-mirror-update} will be computed according to the subgradient matrix, in order to iteratively modify the update and thus adapting to the 
geometry of the space.
% \\[1em]
% Proximal term allows us to build upon the surface of our function, starting from the first order derivative according to Taylor's rule, we build a "parabola" (a strongly convex function in general) using the euclidean norm according to the matrix. In this way, we 
% explore the different "parabolas" over the derivative and according to this we choose the minimum $x$ which give us the $\arg\min$. (?)

\subsection{Convergence Analysis}
\label{sec:convergence}
First of all, let us state that the convergence rate of \texttt{ADAGRAD} is the same of the Stochastic Gradient Descent (\texttt{SGD}), hence $O(1/\sqrt{T})$ but with a lower constant due to the use of $G$ matrix.\\
The algorithm 1 reported in \cite{JMLR:v12:duchi11a} will be applied to our problem and is reported here:\\
{\Large ??}
\begin{flushleft}
  \begin{minipage}{.7\textwidth}
    \begin{algorithm}[H]
      \caption{\texttt{ADAGRAD} for diagonal matrices}
      \label{alg:adagrad}
      \begin{algorithmic}
        \Function{\texttt{ADAGRAD}}{$\eta$,$\delta$}
          \State $x_1 \gets 0$
          \State $\lambda_1 \gets 0$
          \State $g_{1:0} \gets \left[\,\right]$
          \For{$t \gets 1$ to $T$}
            \State $Loss = f_t(x_t)$
            \State $g_t \gets \partial \psi(\lambda_{t-1})$ of $\psi$ at $\lambda_{t-1}$\Comment{Compute subgradient at $\lambda_{t-1}$}
            \State $g_{1:t} \gets \left[ g_{1:t-1}\ g_t \right]$\Comment{Store subgradient}
            \State $s_{t,i} \gets \| g_{1:t,i} \|_2$\Comment{Compute the optimal $s_{t,i}$}
            \State $H_t \gets \delta \mathit{I} + diag(s_t)$
            \State $\Psi_t(\lambda) \gets \frac{1}{2} \left\langle \lambda,H_t \lambda \right\rangle$
            \State Either compute \eqref{eqn:primal-dual-update} or \eqref{eqn:composite-mirror-update} 
          \EndFor
        \EndFunction
      \end{algorithmic}  
    \end{algorithm}
  \end{minipage}
\end{flushleft}
% We should change the iterates $x$ with our iterates $\lambda$. In the following, we will prove the following provided that the iterates are the $\lambda$'s.\\
The general convergence result of this algorithm for both the updates is reported in theorem 5 of the original paper. We will now report the theoretical analysis behind procedure \ref{alg:adagrad} and lastly modify the algorithm in order to match our problem settings.
% \begin{theorem}
%   Let the sequence $\{x_t\}$ be defined by algorithm \ref{alg:adagrad}. For $x_t$ generated using the update \eqref{eqn:primal-dual-update} with $\delta \ge \max_t \|g_t\|_\infty$, for any $x^* \in \mathcal{X}$
%   \[ R_\phi(T) \le \frac{\delta}{\eta} \|x^*\|_2^2 + \frac{1}{\eta} \|x^*\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2 + \eta \sum_{i=1}^d \|g_{1:T,i}\|_2 \]
%   For $x_t$ generated using the update \eqref{eqn:composite-mirror-update}, for any $x^* \in \mathcal{X}$
%   \[ R_\phi(T) \le \frac{1}{2\eta} \max_{t \le T} \|x^* -x_t\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2 + \eta \sum_{i=1}^d \|g_{1:T,i}\|_2 \]
%   \label{th:regrets}
% \end{theorem}
\begin{theorem}
  Let the sequence $\{\lambda_t\}$ be defined by algorithm \ref{alg:adagrad}. For $\lambda_t$ generated using the update \eqref{eqn:primal-dual-update} with $\delta \ge \max_t \|g_t\|_\infty$, for any $\lambda^* \in \mathcal{X}$
  \begin{equation} 
    R_\phi(T) \le \underbrace{\frac{\delta}{\eta} \|\lambda^*\|_2^2 + \frac{1}{\eta} \|\lambda^*\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2}_{\text{\circled{1}}} + \underbrace{\eta \sum_{i=1}^d \|g_{1:T,i}\|_2}_{\text{\circled{2}}} 
    \label{eqn:pd-regret}
  \end{equation}
  For $\lambda_t$ generated using the update \eqref{eqn:composite-mirror-update}, for any $\lambda^* \in \mathcal{X}$
  \begin{equation}
    R_\phi(T) \le \underbrace{\frac{1}{2\eta} \max_{t \le T} \|\lambda^* - \lambda_t\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2}_{\text{\circled{3}}} + \underbrace{\eta \sum_{i=1}^d \|g_{1:T,i}\|_2}_{\text{\circled{2}}} 
    \label{eqn:cm-regret}  
  \end{equation}
  \label{th:regrets}
\end{theorem}
We will now delve into analyzing the different \circled{$\cdot$} parts.\\
First of all, we should recall some intuition in order to understand better the regret bound provided above.\\
Focusin on the algorithm \ref{alg:adagrad}, the chosen value of $s_{t,i}$ explain us why the particular choice of the proximal function $\Psi_t(x) = \frac{1}{2} \left\langle x,H_t x \right\rangle$ is so important. $s_{t,i}$ comes from the solution of the problem
\[ \min_s \sum_{t=1}^T \sum_{i=1}^d \frac{g_{t,i}^2}{s_i} \text{ s.t. } s \succeq 0, \left\langle 1,s \right\rangle \le c \] 
solved by optimizing the Lagrangian
\[ \mathcal{L}(s,\lambda,\theta) = \sum_{i=1}^d \frac{\| g_{1:T,i} \|_2^2}{s_i} - \left\langle \lambda,s \right\rangle + \theta (\left\langle 1,s \right\rangle - c ) \]
Taking the partial derivatives to find the infimum of $\mathcal{L}$, and using the complementary slackness condition on $\lambda_i s_i$ imply that $\lambda_i = 0$. As a consequence, we obtain $s_i = c \| g_{1:T,i} \|_2 / \sum_{j=1}^d \| g_{1:T,j} \|_2$.
Plugging this into the previous objective function, we get
\[ \inf_s \left\lbrace \sum_{t=1}^T \sum_{i=1}^d \frac{g_{t,i}^2}{s_i} : s \succeq 0, \left\langle 1,s \right\rangle \le c \right\rbrace = \frac{1}{c} \left(\sum_{i=1}^d \| g_{1:T,i} \|_2 \right)^2  \]
Now it is natural to suspect that for $s$ achieving the infimum in this latter equation, using a proximal function similar to $\Psi(\lambda) = \left\langle \lambda,diag(s) \lambda \right\rangle$ with associated squared dual norm $\|\lambda\|_{\Psi^*}^2 = \left\langle \lambda,diag(s)^{-1}\lambda \right\rangle$ we should 
lower the gradient terms both in \eqref{eqn:pd-regret} and \eqref{eqn:cm-regret}.\\
The upper bound on the gradient term for both the updates is taken from the \texttt{LEMMA 4} of \cite{JMLR:v12:duchi11a}, stating:
% \begin{lemma}
%   Let $g_t = f_t'(x_t)$ and $g_{1:t}$ and $s_t$ be defined as in algorithm \ref{alg:adagrad}. Then 
%   \[ \sum_{t=1}^T \left\langle g_t,diag(s_t)^{-1}g_t \right\rangle \le 2 \sum_{i=1}^d \|g_{1:t,i}\|_2 \]
% \end{lemma}
\begin{lemma}
  Let $g_t = \psi'(\lambda_t)$ and $g_{1:t}$ and $s_t$ be defined as in algorithm \ref{alg:adagrad}. Then 
  \[ \sum_{t=1}^T \left\langle g_t,diag(s_t)^{-1}g_t \right\rangle \le 2 \sum_{i=1}^d \|g_{1:T,i}\|_2 \]
\end{lemma}
To obtain a bound, we need to consider the terms consisting of the dual-norm of the subgradient in the bounds \eqref{eqn:pd-regret} and \eqref{eqn:cm-regret}, which is $\|\psi'(\lambda_t)\|_{\Psi_t^*}^2$. When we choose $\Psi_t(\lambda) = \left\langle \lambda,(\delta I + diag(s_t)) \lambda \right\rangle$, the associated dual norm is
\[ \| g \|_{\Psi_t^*}^2 = \left\langle g,(\delta I + diag(s_t))^{-1} g \right\rangle\]
Following from the definition of $s_t$ in \ref{alg:adagrad}, we clearly have $\|\psi'(\lambda_t)\|_{\Psi_t^*}^2 \le \left\langle g_t, diag(s_t)^{-1} g_t \right\rangle$. Thus we have the following implication
\[ \sum_{t=1}^T \|\psi'(\lambda_t)\|_{\Psi_t^*}^2 \le \sum_{i=1}^d \|g_{1:T,i}\|_2 \]
which prove the regret term \circled{2}.\\
%QUIQUI
Consequently, it remains to prove the bound over the Bregman divergence and the term $\Psi_T(\lambda^*)$ of proposition 2.1 and 2.2. Focusing on the composite mirror descent, we have:
\begin{align*}
  B_{\Psi_{t+1}} (\lambda^*, \lambda_{t+1}) - B_{\Psi_{t}} (\lambda^*, \lambda_{t+1}) = \frac{1}{2} \left\langle \lambda^* - \lambda_{t+1}, diag(s_{t+1} - s_t)(\lambda^* - \lambda_{t+1}) \right\rangle \\
  \le \frac{1}{2} \max_i (\lambda_i^* - \lambda_{t+1,i})^2 \| s_{t+1} - s_t \|_1
\end{align*}
Since $\| s_{t+1} - s_t \|_1 = \left\langle s_{t+1} - s_t, 1 \right\rangle$ and $\left\langle s_T,1 \right\rangle = \sum_{i=1}^d \| g_{1:T,i} \|_2$ we have
\begin{align*}
  \sum_{t=1}^{T-1} B_{\Psi_{t+1}} (\lambda^*, \lambda_{t+1}) - B_{\Psi_{t}} (\lambda^*, \lambda_{t+1}) \le \frac{1}{2} \sum_{t=1}^{T-1} \| \lambda^* - \lambda_{t+1} \|_\infty^2 \left\langle s_{t+1} - s_t, 1 \right\rangle \\
  \le \frac{1}{2} \max_{t \le T} \|\lambda^* - \lambda_t\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2 - \frac{1}{2} \|\lambda^* - \lambda_1\|_\infty^2 \left\langle s_1,1 \right\rangle
\end{align*} 
which prove us the term \circled{3}.\\
Finally, we also have that
\[ \Psi_T(\lambda^*) = \delta \|\lambda^*\|_2^2 + \left\langle \lambda^*, diag(s_T) \lambda^* \right\rangle \le \delta \|\lambda^*\|_2^2 + \|\lambda^*\|_\infty^2 \sum_{i=1}^d \|g_{1:T,i}\|_2 \]
which give us the bound \circled{1}.\\
Performing a few algebraic simplification lead us to a corollary which give us a more intuitive form of the regret bound. Assume that $\mathcal{X}$ is a compact set and set $D_\infty = \sup_{\lambda \in \mathcal{X}} \| \lambda - \lambda^* \|_\infty$, and define
\[ \gamma_T \triangleq \sum_{i=1}^d \| g_{1:T,i} \|_2 = \inf_s \left\lbrace \sum_{t=1}^T \left\langle g_t,diag(s)^{-1} g_t \right\rangle : \left\langle 1,s \right\rangle \le \sum_{i=1}^d \| g_{1:T,i} \|_2, s \succeq 0 \right\rbrace \]
\begin{corollary}
  Assume that $D_\infty$ and $\gamma_T$ are defined as above. For $\{ \lambda_t \}$ generated using the \eqref{eqn:primal-dual-update} with $\eta = \|\lambda^*\|_\infty$, for any $\lambda^* \in \mathcal{X}$ we have
  \begin{align*}
    R_\phi(T) \le 2 \|\lambda^*\|_\infty \gamma_T + \delta \frac{\|\lambda^*\|_2^2}{\|\lambda^*\|_\infty} \le 2 \|\lambda^*\|_\infty \gamma_T + \delta \|\lambda^*\|_1
  \end{align*}
  Using update \eqref{eqn:composite-mirror-update} to generate $\{\lambda_t\}$ and setting $\eta = D_\infty / \sqrt{2}$, we have
  \begin{align*}
    R_\phi(T) \le \sqrt{2} D_\infty \sum_{i=1}^d \| g_{1:T,i} \|_2 = \sqrt{2} D_\infty \gamma_T \\[1em]
  \end{align*}
\end{corollary}
% Consequently, also upper bound for the proximal term and the bregman divergence are obtained in chapter 3 of \cite{JMLR:v12:duchi11a}. Putting together the last lemma result and the proximal terms bounds give us the theorem \ref{th:regrets}. Stated in simpler 
% terms, the goal of the authors is to achieve an asymptotically sub-linear regret, hence having $R_\phi(T) = o(T)$.\\[1em]
All these presented results are respected by our problem. Indeed, as we stated before, our original problem is for sure a convex problem (a quadratic function with positive semidefinite $Q$) and also the constraints are convex (a set of disjoint 
unitary simplices) implying strong duality. As we know from theory, the dual problem is for sure convex, even if the original one it's not. What we should argue is the presence of the constraints on the dual variables.\\
Being \texttt{ADAGRAD} applicable to any convex set $\mathcal{X} \subseteq \mathbb{R}^n$, this is suitable for our problem, since $\mathcal{X} = \{\lambda \ge 0\}$. We will use one of the just explained update, (preferably 
the \textit{primal-dual} one, since we have a general proof of convergence over exactly $\mathbb{R}_+^n$, in \texttt{LEMMA 2} of Appendix A of \cite{Frangioni2017}), compute the update and then project it on the $\lambda$'s constraint set.\\
We expect to achieve an asymptotically sub-linear regret, as the authors showed in their work.


\subsection{General application to our case}
% {\large NON SO SE METTERE ANCHE LE x, È EFFETTIVAMENTE CONVESSO?}\\
In our setting, we aim to solve problem \eqref{eqn:problem} using \eqref{eqn:dual_problem}. We will use $\mathcal{X} = \{ \lambda \ge 0 \}$ as the constraint set of the lagrangian multipliers $\lambda$'s, and $\mathcal{Y} = \{ \sum_{i \in I^k} x_i = 1 \ \forall \, k \in K\}$ 
as the constraint set of the primal variables.\\
To solve the problem \eqref{eqn:primal-dual-update} and \eqref{eqn:composite-mirror-update} in our problem settings, we consider the update of the dual variable $\lambda$. Referring to the problem \eqref{eqn:dual_problem}, we can freely choose  
among three different update rules, in order \eqref{eqn:projection}, \eqref{eqn:primal-dual-update} and \eqref{eqn:composite-mirror-update}:
\begin{equation}
  \begin{gathered}
    \lambda_{t+1} = P_{\mathcal{X}} \{ \lambda_t + \eta\, diag(G_t)^{-1/2} g_t \} \\
    \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle \overline{g}_t,\lambda \right\rangle + \frac{1}{t} \Psi_t(\lambda) \} \\
    \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle g_t,\lambda \right\rangle + B_{\Psi_t} (\lambda,\lambda_t) \}
    \label{eqn:updates}  
  \end{gathered}
\end{equation}
We need to find a minimum for the considered update function and then project it onto the constraint set $\mathcal{X}$.\\
About the terms $\Psi$ and $B_\Psi$, these will be replaced, according to what we have said before,respectively by:
\begin{gather*}
  \Psi_t(\lambda) = \frac{1}{2} \left\langle \lambda,H_t \lambda \right\rangle \\
  B_{\Psi_t} (\lambda,\lambda_t) = \Psi_t(\lambda) - \Psi_t(\lambda_t) - \left\langle \nabla \Psi_t(\lambda_t),\lambda-\lambda_t \right\rangle
\end{gather*}
Regarding the minimum, this can be simply solved by differentiating the function with respect to the variable to be minimized, and setting it equal to $0$. The detailed derivation of each update can be found in the appendix \ref{sec:appendix}.
\begin{subequations}
  \label{eqn:minimized}
  \begin{align}
    \hat{\lambda}_{t+1} = \lambda_t + \eta diag(G_t)^{-1/2} g_t 
    \tag{Update \eqref{eqn:standard-rule}} \\
    \hat{\lambda}_{t+1} = -H_t^{-1} t\, \eta\, \overline{g}_t
    \tag{Update \eqref{eqn:primal-dual-update}} \\
    \hat{\lambda}_{t+1} = \lambda_t + H_t^{-1} \left[ \Psi(\lambda_t) - \eta\, g_t \right] 
    \tag{Update \eqref{eqn:composite-mirror-update}}
  \end{align}
\end{subequations}
For the stepsize $\eta$, this can be fixed apriori, by using the classical DSS or Polyak stepsize.\\
 For the dual variables, after we obtain the $\hat{\lambda}_{t+1}$, we use the projection over the nonnegative orthant to get $\lambda_{t+1}$, formally
\[
  \lambda_{t+1} = P_\mathcal{X}(\hat{\lambda}_{t+1}) = \max{ \{ 0,\hat{\lambda}_{t+1} \} }
\]
which is a trivial problem tackled many times in the literature \cite{nonnegative-orthant}.\\
% Projection over non negative orthant is a trivial problem and is solved by simply maximizing componentwise $\lambda_t$ between $\left[ 0,P_\mathcal{X}(\hat{\lambda}_t) \right]$ (FORSE NON PROPRIO, LA PROIEZIONE NON È EUCLIDEA MA IN BASE ALLA MATRICE $G$).\\
We need also to derive an update for the primal variables, which are needed at each iteration in order to compute the dual function $\psi( \lambda )$ and the gradient $\nabla_\lambda \psi( \lambda )$. Given the previous multiplier value $\lambda_t$
\[
  x_{t+1} = \argmin_{x \in \mathcal{Y}} \{ x^T Q x + q x - \left\langle \lambda_t,x \right\rangle \}
\]
We need to solve the lagrangian relaxation of a convex quadratic problem, depending on equality constraints made up of disjoint simplices. The constraint set $\mathcal{Y}$ can be rewritten in a matrix form $Ax = b$, where the vector $b$ is a $k \times 1$ vector of all ones, and the matrix $A$
can be derived with the following simple algorithm:
\begin{flushleft}
  \begin{minipage}{.7\textwidth}
    \begin{algorithm}[H]
      \caption{Construct matrix $A$}
      \begin{algorithmic}
        \Procedure{Construct\_$A$}{$K,\left[I^k\right]$}
          \State $A \gets \left[\,\right]$\Comment{Initialize $k \times n$ empty matrix}
          \For{$k \gets 1$ to $K$}
            \State $a_k \gets zeros(n,1)$\Comment{$n \times 1$ empty row vector}
            \For{$i \gets 1$ to $n$}
              \If{$i \in I^k$}\Comment{Check if index $i$ is in the set $I^k$}
                \State $a_k[i] \gets 1$
              \EndIf
            \EndFor
            \State $A[k,:] \gets a_k$
          \EndFor
        \EndProcedure
      \end{algorithmic}
    \end{algorithm}
  \end{minipage}  
\end{flushleft}
Using the {\bf KKT} (Karush-Kuhn Tucker) conditions, we can solve the problem directly through linear algebra by constructing the following linear system:
\begin{gather*}
  \begin{cases}
    Q x + q - \lambda_t + \mu A = 0 \\
    A x - b = 0
  \end{cases}
  \implies 
  \begin{cases}
    Q x + \mu A = \lambda_t - q \\
    A x \quad \quad \:\ \,= b 
  \end{cases}
  \boldsymbol{\implies} 
  \begin{bmatrix}
    Q & A^T \\[1ex]
    A & 0 
  \end{bmatrix}
  \begin{bmatrix}
    x \\[1ex]
    \mu
  \end{bmatrix}
  = 
  \begin{bmatrix}
    \lambda_t - q \\[1ex]
    b
  \end{bmatrix}
\end{gather*}
a linear system that can be solved directly and efficiently by computing the pivoted LU factorization of the matrix and save it for the next iterations. Hence, using the LU factorization:
% a least squares problem that can be solved directly by computing the QR factorization of the matrix and save it for the next iterations. Hence, using the QR factorization and the orthogonality of the factorization matrix $\widehat{Q}$
% \begin{gather*}
%   \begin{bmatrix}
%     Q & A^T \\[1ex]
%     A & 0 
%   \end{bmatrix}
%   = 
%   \widehat{Q} R 
%   \boldsymbol{\implies}
%   \widehat{Q} R 
%   \begin{bmatrix}
%     x \\[1ex]
%     \mu
%   \end{bmatrix}
%   = 
%   \begin{bmatrix}
%     \lambda_t - q \\[1ex]
%     b
%   \end{bmatrix}
%   \boldsymbol{\implies} 
%   R 
%   \begin{bmatrix}
%     x \\[1ex]
%     \mu
%   \end{bmatrix} 
%   = 
%   \widehat{Q}^T 
%   \begin{bmatrix}
%     \lambda_t - q \\[1ex]
%     b
%   \end{bmatrix}
% \end{gather*}
\begin{gather*}
  \begin{bmatrix}
    Q & A^T \\[1ex]
    A & 0 
  \end{bmatrix} 
  \begin{bmatrix}
    x \\[1ex]
    \mu
  \end{bmatrix}
  = 
  \begin{bmatrix}
    \lambda_t - q \\[1ex]
    b
  \end{bmatrix}
  \boldsymbol{\implies} 
  \begin{bmatrix}
    x \\[1ex]
    \mu
  \end{bmatrix}
  = 
  \begin{bmatrix}
    Q & A^T \\[1ex]
    A & 0 
  \end{bmatrix}^{-1}
  \begin{bmatrix}
    \lambda_t - q \\[1ex]
    b
  \end{bmatrix}
  \boldsymbol{\implies} 
  \begin{bmatrix}
    x \\[1ex]
    \mu
  \end{bmatrix}
  = 
  U^{-1} * \left(L^{-1} * \left(P * \begin{bmatrix}
    \lambda_t - q \\[1ex]
    b
  \end{bmatrix}\right) \right)
\end{gather*}
which can be solved efficiently through forward substitution (for the matrix $L$) and back substitution (for the matrix $U$) with a complexity of $O((n+K)^2)$.\\
Lastly, regarding the stopping condition for the algorithm termination, we can check primal and dual variables. Follows that, given a certain value of tolerance $\epsilon$, we have %respectively for the primal and dual variables
\begin{equation}
  \begin{gathered}
    \|x_{t} - x_{t-1}\|_2 \le \epsilon \\
    \|\lambda_{t} - \lambda_{t-1}\|_2 \le \epsilon
  \end{gathered}
  \label{eqn:stopping-condition}
\end{equation}
In addition to this, what we can check too is the duality gap between the original function and the dual function (provided that we know the optimal value), so
\begin{gather*}
  f(x) - \psi(\lambda) \\
  f(x) - f(x^*) \le f(x) - \psi(\lambda)
\end{gather*}
From this we understand that having a zero duality gap implies optimality of the solution.\\ 
Putting everything together, we obtain a slightly different algorithm than \ref{alg:adagrad}:
\begin{flushleft}
  \begin{minipage}{.7\textwidth}
    \begin{algorithm}[H]
      \caption{\texttt{ADAGRAD} on our dual problem}
      \label{alg:my_alg}
      \begin{algorithmic}
        \Function{\texttt{ADAGRAD}}{$\eta$, $\delta$, $\epsilon$, $max\_iter$}
          \State $\lambda_0 \gets 0$
          \State $g_{1:0} \gets \left[\,\right]$
          \State $x_0 \gets 0$
          \For{$t \gets 1$ to $T$}
            \State $Loss \gets f(x_{t-1})$
            \State $g_t \gets \dfrac{\partial \psi_\lambda(\lambda)}{\partial \lambda}$\Comment{Compute subgradient}
            \State $g_{1:t} \gets \left[ g_{1:t-1}\ g_t \right]$\Comment{Store subgradient}
            \State $s_{t,i} \gets \| g_{1:t,i} \|_2$\Comment{Solution of the problem \ref{sec:convergence}}
            \State $H_t = \gets \delta \mathit{I} + diag(s_t)$
            \State $\Psi_t(\lambda_{t-1}) \gets \frac{1}{2} \left\langle \lambda_{t-1},H_t \lambda_{t-1} \right\rangle$  
            \State $x_t = \argmin_{x \in \mathcal{Y}} \left\lbrace x^T Q x + q x - \left\langle \lambda_{t-1},x \right\rangle \right\rbrace$\Comment{Solution of Lagrangian relaxation}
            \State $\hat{\lambda}_t =$ one among $\eqref{eqn:updates}$
            \State $\lambda_t = P_\mathcal{X}(\hat{\lambda}_t)$ 
            \State Check stopping conditions \eqref{eqn:stopping-condition} or $max\_iter$ reached
          \EndFor
        \EndFunction
      \end{algorithmic}  
    \end{algorithm}
  \end{minipage}
\end{flushleft}

\section{Implementation}
The ideas above described have been implemented using Julia. The provided package give the user the ability to provide the dimension of the problem $n$ and the number of simplices $K$ by input.\\
Subsequently, the code is all automated and provide the creation of the matrix $Q \succeq 0$, $A$, the random sets $I^k$, the vector $q$ and all the required parameters. The resulting solutions 
of the three different update rules are saved and compared with the optimal primal solution $f(x^*)$ found using the external package \textit{Convex.jl}.\\
Also, there are some hyperparameters which can be modified by the user inside \textit{main.jl}, like the maximum number of iterations and the $\epsilon$ value to check the $\lambda$ variation.\\
All the values assumed by $x$, $\lambda$, each $\lambda$-norm, the number of iterations and the value of the Lagrangian function are saved at each iteration in order to display at the end a convergence plot 
(\textit{iterations} vs \textit{Lagrangian value}) and a distance visualization plot of the $\lambda$-norm (\textit{iterations} vs $\lambda$\textit{-norms}).
All the duality gaps and the resulting value of the Lagrangian functions are saved too in a dictionary and printed at the end to identify the best duality gap (among the different update rules) and 
the function value.

\newpage

%Sets the bibliography style to UNSRT and imports the 
%bibliography file "samples.bib".
\bibliographystyle{unsrt}
\bibliography{bibliography}

\newpage

\appendix

\section{Appendix A: Updates derivations}
\label{sec:appendix}
Given a matrix $A$ of size $n \times n$, the proximal term expression of a vector $x$ of size $n\times 1$ at step $t$ is
\[
  \Psi_t(x) = \frac{1}{2} \left\langle x, A x \right\rangle  
\]

\subsection{Differentiating proximal term}
Derivation of proximal term arises from the need of obtaining the $\argmin$ $x$ of a given update function. Starting by the definition
\[
  \frac{\partial \Psi_t(x)}{\partial x} = \frac{1}{2} \frac{\partial}{\partial x} \left\langle x, A x \right\rangle  
\]
The term $y = A x$ is given by:
\begin{align*}
  y = 
  \begin{bmatrix}
    a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n \\[2ex]
    a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n \\[2ex]
    \cdots \\
    a_{n1}x_1 + a_{n2}x_2 + \cdots + a_{nn}x_n 
  \end{bmatrix}
\end{align*}
and then expanding the scalar product we obtain
\begin{align*}
  \left\langle x,y \right\rangle = x_1 y_1 + x_2 y_2 + \cdots + x_n y_n
\end{align*}
Now we can differentiate everything w.r.t. to $x$, obtaining the closed form
\begin{align*}
  \frac{\partial \left\langle x,y \right\rangle}{\partial x} = 
  \begin{bmatrix}
    \dfrac{\partial \left\langle x,y \right\rangle}{\partial x_1} \\[3ex]
    \dfrac{\partial \left\langle x,y \right\rangle}{\partial x_2} \\[3ex]
    \cdots \\[3ex]
    \dfrac{\partial \left\langle x,y \right\rangle}{\partial x_n} 
  \end{bmatrix}
  = 
  \begin{bmatrix}
    2 a_{11}x_1 + \displaystyle \sum_{\mathclap{j=1, j \neq 1}}^n a_{1j} x_j + \sum_{\mathclap{i=1, i \neq 1}}^n a_{i1} x_i \\[4ex]
    2 a_{22}x_2 + \displaystyle \sum_{\mathclap{j=1, j \neq 2}}^n a_{2j} x_j + \sum_{\mathclap{i=1, i \neq 2}}^n a_{i2} x_i \\[4ex]
    \cdots \\[4ex]
    2 a_{nn}x_n + \displaystyle \sum_{\mathclap{j=1, j \neq n}}^n a_{nj} x_j + \sum_{\mathclap{i=1, i \neq n}}^n a_{in} x_i \\
  \end{bmatrix}
\end{align*}

\subsection{Derivation of primal-dual update}
After describing the derivation of the proximal term, we can now look into the detailed derivation of the update \eqref{eqn:primal-dual-update}. Starting from the equation
\[
  \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle \overline{g}_t,\lambda \right\rangle + \frac{1}{t} \Psi_t(\lambda) \} 
\]
we want to achieve the $\argmin$ over the set $\mathcal{X}$. Focusing on the minimum problem, we want to get the minimum $\lambda$, hence:
\begin{align*}
  \frac{\partial}{\partial \lambda} \eta \left\langle \overline{g}_t,\lambda \right\rangle + \frac{\partial}{\partial \lambda} \frac{1}{t} \Psi_t(\lambda) = 0 \\
  \eta\ \overline{g}_t + \frac{1}{2t} \frac{\partial}{\partial \lambda} \left\langle \lambda,H_t \lambda \right\rangle = 0 
\end{align*}  
Knowing that $H_t$ is a diagonal matrix, the summation terms obtained in the derivation of $\Psi$ vanish:
\begin{align*}
  \frac{\partial}{\partial \lambda} \left\langle \lambda, H_t \lambda \right\rangle =
  \begin{bmatrix}
    2 h_{11} \lambda_1 \\[2ex]
    2 h_{22} \lambda_2 \\[2ex]
    \cdots \\[2ex]
    2 h_{nn} \lambda_n \\
  \end{bmatrix}
  = 2\, H_t\, \lambda
\end{align*}
Substituting this into the above derivation, we get the minimum $\lambda$:
\begin{align*}
  \eta\ \overline{g}_t + \frac{1}{t} H_t\, \lambda = 0 \\
  \lambda = - H_t^{-1}\, t\, \eta\, \overline{g}_t
\end{align*}

\subsection{Derivation of composite-mirror update}
We follow the same approach also for the update \eqref{eqn:composite-mirror-update}. Starting from the definition
\[
  \lambda_{t+1} = \argmin_{\lambda \in \mathcal{X}} \{ \eta \left\langle g_t,\lambda \right\rangle + B_{\Psi_t} (\lambda,\lambda_t) \}
\]
where we remark the definition of Bregman divergence
\[
  B_{\Psi_t} (\lambda,\lambda_t) = \Psi_t(\lambda) - \Psi_t(\lambda_t) - \left\langle \nabla \Psi_t(\lambda_t),\lambda-\lambda_t \right\rangle  
\]
Also in this case, to find the $\argmin$ we derive the update formula and set it to be zero
\begin{align*}
  \frac{\partial}{\partial \lambda} \eta \left\langle g_t,\lambda \right\rangle + \frac{\partial}{\partial \lambda} B_{\Psi_t} (\lambda,\lambda_t) = 0 \\ 
  \eta\, g_t + \frac{\partial}{\partial \lambda} \left[ \Psi_t(\lambda) - \Psi_t(\lambda_t) - \left\langle \nabla \Psi_t(\lambda_t),\lambda-\lambda_t \right\rangle \right] = 0 \\
  \eta\, g_t + H_t\, \lambda - \Psi_t(\lambda_t) - \frac{\partial}{\partial \lambda} \left\langle \nabla \Psi_t(\lambda_t),\lambda-\lambda_t \right\rangle = 0
\end{align*}
Considering the first term of the scalar product, we have to evaluate the first order taylor model of the proximal function $\Psi_t$ at the
known quantity $\lambda_t$. It is easy to see that by using the derivation in the first paragraph and the fact that $H_t$ is diagonal
\begin{align*}
  \nabla \Psi_t(\lambda_t) = \nabla \dfrac{1}{2} \left\langle \lambda_t, H_t \lambda_t \right\rangle = H_t \lambda_t
\end{align*}
Putting this into equation
\begin{align*}
  \frac{\partial}{\partial \lambda} \langle H_t \lambda_t, \lambda - \lambda_t \rangle = \frac{\partial}{\partial \lambda} \sum_{i=1}^n h_{ii} \lambda_{t,i} (\lambda_i - \lambda_{t,i})
\end{align*}
And so is easy to see that
\begin{align*}
  \dfrac{\partial}{\partial \lambda} \langle H_t \lambda_t, \lambda - \lambda_t \rangle = 
  \begin{bmatrix}
    \dfrac{\partial}{\partial \lambda_1} \langle H_t \lambda_t, \lambda - \lambda_t \rangle \\[3ex]
    \dfrac{\partial}{\partial \lambda_2} \langle H_t \lambda_t, \lambda - \lambda_t \rangle \\[3ex]
    \cdots \\[3ex]
    \dfrac{\partial}{\partial \lambda_n} \langle H_t \lambda_t, \lambda - \lambda_t \rangle
  \end{bmatrix} 
  =
  \begin{bmatrix}
    h_{11} \lambda_{t,1} \\[2ex]
    h_{22} \lambda_{t,2} \\[2ex]
    \cdots \\[2ex]
    h_{nn} \lambda_{t,n}
  \end{bmatrix}
  = 
  H_t \lambda_t
\end{align*} 
And finally putting this into the main problem, we get:
\begin{align*}
  \eta\, g_t + H_t\, \lambda - \Psi_t(\lambda_t) - H_t \lambda_t = 0 \quad \implies \\
  \lambda = - H_t^{-1} \left[ \eta\, g_t - \Psi(\lambda_t) - H_t \lambda_t \right] = \lambda_t + H_t^{-1} \left[ \Psi(\lambda_t) - \eta\, g_t \right] 
\end{align*}


\section{Appendix B: subgradient computation}

Utterly following the definition, we state that $s$ is a subgradient of $\psi$ at $\lambda_{t-1}$
\[
  \psi(y) \ge \psi(x) + s(y-x) \quad \forall y \in \mathbb{R}^n  
\]
having then 
\[
  \partial \psi(\lambda_{t-1}) = \{ s \in \mathbb{R}^n : s \text{ is a subgradient at } \lambda_{t-1} \}
\]

In order to have our ascent direction of our dual function, we need to compute the subgradient of the $\psi$ function at the previous point $\lambda_{t-1}$
\begin{align*}
  \dfrac{\partial \psi_\lambda(\lambda_{t-1})}{\partial \lambda_{t-1}}
\end{align*}
where the $\psi$ function coincide with the Lagrangian relaxation, hence
\begin{align*}
  \dfrac{\partial}{\partial \lambda_{t-1}} x^T Q x + q x - \left\langle \lambda_{t-1},x \right\rangle
\end{align*}
Assuming we are at step $t$ of our iterations, then we will use the primal variable $x_{t-1}$ obtained in the previous step. As a consequence the gradient is simply given by
\[
  \dfrac{\partial \psi_\lambda(\lambda_{t-1})}{\partial \lambda_{t-1}} = - x_{t-1}
\]



\end{document}
